<!DOCTYPE html>
<html lang = "en">
    <head>
        <meta charset = "UTF-8">
        <meta name = "viewport" content="width=device-width, initial-scale=1.0">
        <title>Ben Austin > Web Scraping</title>
        <link rel = "stylesheet"
        href = "https://cdnjs.cloudfare.com/ajax/libs/normalize/7.0.0/normalize.min.css">
        <link rel = "stylesheet"
        href = "https://cdnjs.cloudfare.com/ajas/libs/font-awesome/5.11.2/css/all.css"
        integrity = "sha256-46qynGAkLSFpVbEBog43gvNhfr0j+BmwXdxFgVK/Kvc=" crossorigin="anonymous" />
        <script src="https://kit.fontawesome.com/1d82a883f3.js" crossorigin="anonymous"></script>
        <script src="https://d3js.org/d3.v3.js"></script>
        <script src="https://d3js.org/topojson.v1.min.js"></script>
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,900|Source+Sans+Pro:300,900&display=swap" rel="stylesheet">
        <link rel = "stylesheet" href = "css/style.css">
    </head>
    <body>
        <header>
            <div class= "logo">
                <li class= "logo-list">
                    <a class = "logo" href = "index.html">
                        <i class="fas fa-bold"></i>
                    </a>
                </li>
            </div>
            <button class = "nav-toggle" aria-label="toggle navigation">
                <span class = "hamburger"></span>
            </button>
            <nav class = "nav">
                <ul class="nav__list">
                    <li class = "nav__item"><a href = "index.html" class = "nav__link">Home</a></li>
                    <li class = "nav__item"><a href = "index.html#services" class = "nav__link">My Services</a></li>
                    <li class = "nav__item"><a href = "index.html#about" class = "nav__link">About me</a></li>
                    <li class = "nav__item"><a href = "index.html#work" class = "nav__link">My Work</a></li>
                    <li class = "nav__item"><a href = "d3_page.html" class = "nav__link">d3.js</a></li>
                </ul>
            </nav>
        </header>

        <section class="intro" id="home">
            <h1 class = "section__title section__title--intro">
                Web Scraping with <strong>Python</strong>
            </h1>
            <p class = "section__subtitle section__subtitle--intro"></p>
            <img src="img/BS.png" class = "intro__image">
        </section>

        <section class = "d3-post">
            <div class = "d3-post d3-post--subtitle">
                <p class = "d3-post d3-post--subtitle--text">
                    Creating a webscraper
                </p>
            </div>
            <p class = "d3-post d3-post--content--text">
                I embarked on my development journey to learn Python midway through 2021. One of the drivers for my desire to enhance my coding skills in a popular language such as Python was to automate tasks in my day to day life. 
                Working as a Data Visualisation and Automation Analyst for Sainsbury's opened my eyes to what is possible with languages such as Python, using some very powerful packages.
                After using retail investor apps to manage my personal finances, I found that one of the most valuable features were price notifications for certain stocks and funds. Having automatic notifications setup meant that I didn't have to worry about checking prices, as I knew I would receive a push notification if there were any significant market swings.  <br/>  <br/>
                I wanted to bring this functionality to cryptocurrency monitoring. <br/> <br/>
                As crypto is such a volatile asset to hold, large price swings are common, and due to the 24/7 nature of the market, may occur while the holder is asleep, or unable to react to the market changes. Bringing price notification monitoring to crypto would allow an investor to be notified of changes, without having to check the price of the asset. <br/> 
                Using this premise as a driver for my Python project, I built a web scraper to do just this; the mechanics of which I will outline below.
            </p>
            <div class = "d3-post d3-post--subtitle">
                <p class = "d3-post d3-post--subtitle--text">
                    Choosing your weapon
                </p>
            </div>
            <p class = "d3-post d3-post--content--text">
                When it comes to web scraping, there are two main weapons in the arsenal of the developer: Beautiful Soup or Selenium. The choice between these two incredibly powerful packages was the first step in my journey to create the web scraper I desired. The choice between the two should be down to use case. 
                Beautiful Soup is a parser that can be used to parse html and extract objects within in. Selenium is a functional acceptance API, allowing users to built programs to test web pages, this includes the ability to interact with a webpage, as well as extract elements. Selenium is very powerful as it can be used to access data behind login screens, buttons, clicks in a webpage. <br/> I knew where my data was, and it was easily accessible, no login pages, no buttons, no clicks.
                This meant that for my use case in this project, the services I required were that of Beautiful Soup. I am currently working on a slightly more functional version of the script that uses Selenium instead, but for now, Beautiful Soup will very much suffice.
            </p>
            <div class = "d3-post d3-post--subtitle">
                <p class = "d3-post d3-post--subtitle--text">
                    Extracting an HTML Element
                </p>
            </div>
            <p class = "d3-post d3-post--content--text">
                Using Beautiful Soup is really easy, all we need is 4 lines of code to extract an html element. The code to do so is below: 
            </p>
            <div class = "d3-post d3-post--code">
                <p class = "d3-post d3-post--code--text">
                    url1 = 'your_website_of_choice' <br/>
                    req1 = requests.get(url1)<br/>
                    soup1 = BeautifulSoup(req1.text,'html.parser') <br/>
                    temp1 = soup1.find_all('div', class_ = 'priceValue smallerPrice')<br/>
                </p>
            </div>
            <p class = "d3-post d3-post--content--text">
                First of all, we intiialise a website URL, this is the site that I needed to scrape, but any website will do. The next line sends a request to the website, and the third line uses Beautiful Soup to parse the html. At this stage, we have full access to the html so we can search it for elements. Using a web dev kit for chrome or safari we can inspect the element that we need and figure out how to access it. 
                The best way for my element was to access a div with the given class name 'priceValue smallerPrice'. You can drill more if needed once inside a div using dot notion, e.g. temp1.p.text would access the paragraph element inside temp1, we need to '.text' to convert to a Python string. Float can then be parsed if a number is needed. 
                Beautiful Soup has done then hard work for us here, we have the live price of a cryto in our Python Script. I now needed to determine a way of notification.
            </p>
            <div class = "d3-post d3-post--subtitle">
                <p class = "d3-post d3-post--subtitle--text">
                    Price Drop Notifications
                </p>
            </div>
            <p class = "d3-post d3-post--content--text">
                Extracting the current price is all well and good, but useless if there is no way of the script notifying the user of a change in price. The way that I tackled this problem was storing the price everytime the script ran in a text file. The script would then access the last line of the text file and check for a significant enough difference, which I set at 10%.
                If the price were to drop by more than 10%, then I used the following code to ping a website, which would trigger an IFTTT module to send my phone a notification.
            </p>
            <div class = "d3-post d3-post--code">
                <p class = "d3-post d3-post--code--text">
                    if float(price) < prev_price*(1-buffer): <br/>
                    &nbsp; &nbsp; &nbsp; &nbsp;requests.post(trigger_url)<br/>
                    &nbsp; &nbsp; &nbsp; &nbsp;print("Low value notification sent")<br/>
                    &nbsp; &nbsp; &nbsp; &nbsp;text_file = open("Price.txt","a")<br/>
                    &nbsp; &nbsp; &nbsp; &nbsp;text_file.write("\n" + str(datetime.datetime.now())[0:19] + " " + price)<br/>
                    &nbsp; &nbsp; &nbsp; &nbsp;text_file.close()
                </p>
            </div>
            <p class = "d3-post d3-post--content--text">
                The last lines of the above code updates the price to the new, lower price, which then becomes the baseline for the script to test against. A similar process is completed if the price is more than 10% higher than the previous price, but a notification is not sent in this instance.
            </p>
            <div class = "d3-post d3-post--subtitle">
                <p class = "d3-post d3-post--subtitle--text">
                    Final Touches
                </p>
            </div>
            <p class = "d3-post d3-post--content--text">
                The core functionality of the script is detailed above; however I made some quality of life enhancements after the core script was working. Building in email notifications was the first enhancement. This allowed me to send more information when a price drop was notified. I included the price, asset value, a graph and website links in the email, so that all infomation was quickly accessible when a drop was noticed.
                The second was deploying the script to run 24/7. To achieve this, I used a RaspberryPi. Deploying the script to the Pi was really easy, and running the script on a schedule was also easy to setup. The script is currently running every 10 minutes, and has been 24/7 for just over 2 months at the time of writing. After building in some error checking incase the internet connection went down, or the target website hung, the script very rarely errors; and if it does, I get a notification, so that I can quickly get it up and running again. <br/> <br/>
                Overall this project was a really interesting way to enchance my Python skills. Tackling new modules including Beautiful Soup was a good challenege and has provided me with some very powerful web scraping skills that could be used to a whole variety of purposes! Feel free to contact me if you are interested in the script, or have any questions.
            </p>
        </section>

        <footer class = "footer">
            <a href="mailto:benaustin27@gmail.com" class = "footer__link">benaustin27@gmail.com</a>
            <ul class = "social-list">
                <li class = "social-list__item">
                    <a class = "social-list__link" href = "facebook.com">
                        <i class="fab fa-facebook"></i>
                    </a>
                </li>
                <li class = "social-list__item">
                    <a class = "social-list__link" href = "instagram.com">
                        <i class="fab fa-instagram"></i>
                    </a>
                </li>
                <li class = "social-list__item">
                    <a class = "social-list__link" href = "github.com">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
            </ul>
        </footer>
        <script src="js/index.js"></script>
        </div>
    </body>
</html>